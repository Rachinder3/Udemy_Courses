Goals:
    Understand CV applications
    Learn Open CV
    Create applications with this understanding


To create environment and install dependencies in a yaml file:
    conda env create -f "Yaml name" 


==============================================================


Section 2: 

Numpy and Image basics


]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]


Numpy arrays:

Importing:


import numpy as np





arange :

np.arange(0,10)



zeroes:

np.zeros((5,5))



setting seed:


np.random.seed(101) 
arr = np.random.randint(0,100,10)



max:
arr.max()


argmax:

arr.argmax()


reshape:

arr.reshape(2, -5)



Indexing:

max[0,1]


mat[0:3, 0:3]




copy: does deep copy

]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]


What is an image:


How does computer identify image??

Each image can be represented as an array.

How dark a pixel can be represented as a value b/w 0 and 1

Default images have values b/w 0 and 255

The range 0 to 255 has to do with how computers store 8-bit numbers

To normalize these values, we divide by 255.



Color images: 

Color images can be represented in 3 channels : Red, Green, Blue

RGB allows us to produce a range of colors.

Each channel will have different intensity of that color.

The shape of these image arrays have 3 dimensions:
    height, width and color channels


Computer won't know a channel us RED, it just knows that there are 3 different channels.

The user dictates which channel is which. Each channel alone is a essentially same as greyscale image.


]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]


Images and Numpy:


### If we plot the path instead of image iteself, this error is encountered. Instead load the image first





## Will mostly use Open CV, for now using PIL.Image class instead





from PIL import Image
pic = Image.open(path)




## Should use imread function of matplotlib to read this, no need to use the above one

img = plt.imread(path)  ## This will work fine


## If using Image class, use asarray function to convert to array



## working on individual channles

r = img[:,:,0]
g = img[:,:,1]
b = img[:,:,2]


plt.imshow(r, cmap='binary')


pic_red = img.copy()

pic_red[:, :, 1] = 0    # Zero out contribution from green
pic_red[:, :, 2] = 0    # Zero out contribution from blue


plt.imshow(pic_red)

//////////////////////////////////////////////////////////////////////////



============================================================================

Section 3:
Image Basics with Open CV

Introduction:


Open CV:
    library of programming functions aimed at real-time Computer Vision

    Created by Intel in 1999, written in CPP

    Still really popular in CPP


    Contains many popular algos for CV, including objefct detection

    
Section Agenda: 

    Open image files with Open CV be it with ipynb notebooks or python script

    Draw simple geometries on images(ex: draw Bounding boxes while doing Object Detection/ Tracking)

    Directly interact with an image through callbacks




Object Tracking: Continuous detection of same object in video

Object Detection: Object Detection in a single frame



///////////////////////////////////////////////////////////////




path = r"C:\\Users\\rachi\\Desktop\\Udemy_Courses\\Python for Computer Vision with OpenCV and Deep Learning\\Materials\\Computer-Vision-with-Python\\DATA\\00-puppy.jpg"


Opening images in notebooks with Open CV:




importing: 

import cv2




Loading images:

path = 'wrong_path'
cv2.imread(path)  ## even though path is wrong, doesn't generate error. Gives none instead
### This can lead to errors so we should check type of image after loading before going ahead



path = r"C:\\Users\\rachi\\Desktop\\Udemy_Courses\\Python for Computer Vision with OpenCV and Deep Learning\\Materials\\Computer-Vision-with-Python\\DATA\\00-puppy.jpg"

img = cv2.imread(path)

img  ## Outputs the image as a numpy array




*** By default channels in Open CV are BGR and not RGB


The image has been correctly loaded by openCV as a 
numpy array, but the color of each pixel has been 
sorted as BGR.

Matplotlib's plot expects an RGB image so, 
for a correct display of the image, it is 
necessary to swap those channels. 

This operation can be done either by using 
openCV conversion functions cv2.cvtColor() or 
by working directly with the numpy array.





cv2.cvtColor():

takes image array and code for conversion.

codes need to be integers.

They are there by default in cv2 library. cv2.COLOR_BGR2RBG, converts images from BGR to RGB


Ex:

img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)



Reading img as greyscale:

## Read in greyscale altogether, instead of doing conversion

img_grey_scale = cv2.imread(path, cv2.IMREAD_GRAYSCALE)

plt.imshow(img_grey_scale, cmap = 'gray')






Reshaping images:


img_reshaped = cv2.resize(img, (800,400)) ## ** 800 is resizing for 1950 instead of 1300, cv2 takes it opposite


plt.imshow(img_reshaped)




### with ratios

## function footprint is wierd here


w_ratio = 0.5
h_ratio = 0.5

### reducing image by 50 %

new_img = cv2.resize(img, (0,0), img,w_ratio, h_ratio)

## first take (0,0) then pass image again and then pass ratios




## flipping images

flip(src, flipCode[, dst]) -> dst
.   @brief Flips a 2D array around vertical, horizontal, or both axes.




flipped_img = cv2.flip(img, 0)  ### returns water image

flipped_img = cv2.flip(img, 1) ### return mirror Image


flipped_img = cv2.flip(img, -1)  ### flips across both axes


### These can help in Data Augmenatation





Saving image files


Use cv2.imwrite() function

### This will store the BGR version of Image



Larger displays in notebooks

fig = plt.figure(figsize=(10,8))
ax = fig.add_subplot(111)
ax.imshow(new_img)



Opening images out of jupyter notebooks


Sometimes we want to use opencv on its own to display images in 
their own window.

Often jupyter interferes with closing of window.





import cv2

img = cv2.imread(path)

while True:
    cv2.imshow('Puppy',img) ## see, we are using cv2's imshow instead of matplotlib's imshow
    
    ## explanation for this line
    # https://stackoverflow.com/questions/35372700/whats-0xff-for-in-cv2-waitkey1/39201163
    
    if cv2.waitKey(1) & 0xFF == 27: # IF we've waited at least 1 ms AND we've pressed the Esc
        break

cv2.destroyAllWindows()


### we can't resize this image in seperate window

## 27 is the number of escape key



//////////////////////////////////////////////////////////////////////


Drawing on images


generating blank image:

blank_img = np.zeros((512,512,3), dtype = 'int16')



rectangle:

cv2.rectangle



rectangle(img, pt1, pt2, color[, thickness[, lineType[, shift]]])


Ex:

rect_img = cv2.rectangle(blank_img, pt1= (0,0),pt2=(510,128), color = (122,131,21), thickness=5)


## directly adds in the image inplace



********
### while drawing figures in images using cv2

coordinates given as x,y

x is the horizontal axis and y is vertical axis. starts from left 

Better to leave axis on as it shows x and y axis.  starts from top and not bottom.


While giving color, we use rgb code only

******
Great idea to keep axis on and use it for reference



Circles:

circle(img, center, radius, color[, thickness[, lineType[, shift]]]) -> img
.   @brief Draws a circle.
.   
.   The function cv::circle draws a simple or filled circle with a given center and radius.
.   @param img Image where the circle is drawn.
.   @param center Center of the circle.
.   @param radius Radius of the circle.
.   @param color Circle color.
.   @param thickness Thickness of the circle outline, if positive. Negative values, like #FILLED,
.   mean that a filled circle is to be drawn.
.   @param lineType Type of the circle boundary. See #LineTypes
.   @param shift Number of fractional bits in the coordinates of the center and in the radius value.


Normal circle
cv2.circle(blank_img, center = (100, 400), radius = 100, thickness = 2, color = (255,0,0))


Filled in circle:  Give thickness as -1
cv2.circle(img=blank_img,center=(100,100), radius=100, color = (0,255,0),thickness=-1)




Lines:

line(img, pt1, pt2, color[, thickness[, lineType[, shift]]]) -> img
.   @brief Draws a line segment connecting two points.
.   
.   The function line draws the line segment between pt1 and pt2 points in the image. The line is
.   clipped by the image boundaries. For non-antialiased lines with integer coordinates, the 8-connected
.   or 4-connected Bresenham algorithm is used. Thick lines are drawn with rounding endings. Antialiased
.   lines are drawn using Gaussian filtering.
.   
.   @param img Image.
.   @param pt1 First point of the line segment.
.   @param pt2 Second point of the line segment.
.   @param color Line color.
.   @param thickness Line thickness.
.   @param lineType Type of the line. See #LineTypes.
.   @param shift Number of fractional bits in the point coordinates.


cv2.line(img = blank_img, pt1 = (0,0), pt2 = (511,511), color = (200,200,200), thickness=4)




Text:

Docstring:
putText(img, text, org, fontFace, fontScale, color[, thickness[, lineType[, bottomLeftOrigin]]]) -> img
.   @brief Draws a text string.
.   
.   The function cv::putText renders the specified text string in the image. Symbols that cannot be rendered
.   using the specified font are replaced by question marks. See #getTextSize for a text rendering code
.   example.
.   
.   @param img Image.
.   @param text Text string to be drawn.
.   @param org Bottom-left corner of the text string in the image.
.   @param fontFace Font type, see #HersheyFonts.
.   @param fontScale Font scale factor that is multiplied by the font-specific base size.
.   @param color Text color.
.   @param thickness Thickness of the lines used to draw a text.
.   @param lineType Line type. See #LineTypes
.   @param bottomLeftOrigin When true, the image data origin is at the bottom-left corner. Otherwise,
.   it is at the top-left corner.


## First specify the font

font = cv2.FONT_HERSHEY_DUPLEX

## can see other fonts just have to use intelliprompt on cv.COLOR_BGR2RBG

cv2.putText(blank_img, text = "RACHin", org=(400,200), fontFace=font, fontScale=1, thickness=4, lineType=cv2.LINE_4, color = (255,255,255))

## for line as well, we need to use intelliprompt




custom polygon:

cv2.polylines:

Docstring:
polylines(img, pts, isClosed, color[, thickness[, lineType[, shift]]]) -> img
.   @brief Draws several polygonal curves.
.   
.   @param img Image.
.   @param pts Array of polygonal curves.
.   @param isClosed Flag indicating whether the drawn polylines are closed or not. If they are closed,
.   the function draws a line from the last vertex of each curve to its first vertex.
.   @param color Polyline color.
.   @param thickness Thickness of the polyline edges.
.   @param lineType Type of the line segments. See #LineTypes
.   @param shift Number of fractional bits in the vertex coordinates.





blank_img = np.zeros((512,512,3))



### decide vertices first, make sure vertices make sense
vertices = np.array([[100,400],[200,200],[400,400]])


## open cv wants these vertices in a specific order.

## Always these dimensions are used. We reshape to (-1,1,2)

pts = vertices.reshape(-1,1,2)  ## this is just adding dimension on 2nd axis. 1st axis contains number of point, 3 rd dimension contains the data for that point


## we have to pts as list. so we enclose pts around square brackets
cv2.polylines(blank_img, pts = [pts], isClosed= True, color = (123,53,123), thickness=5)




Majorly we use cv2.rectangle to draw Bounding boxes around objects.


////////////////////////////////////////////////////////////////

Direct drawing on images with a mouse:


can use callbacks to connect images to event functions with Open CV.

This allows us to directly interact with images (later on videos)



3 parts:
    Connecting callback functions
    
    Adding Functionality throgh Event choices

    Dragging the mouse for Functionality





#### Function
def draw_circle(event, x, y, flags, params):   ### event: automatically passed. x,y : current coordinates of the mouse
    if event == cv2.EVENT_LBUTTONDOWN:  ### draw as soon as we clicked down
        cv2.circle(img, (x,y), 100,(0,255,0), -1)


### connect function to the callback

cv2.namedWindow(winname="my_drawing") # This names the window so we can reference it 

cv2.setMouseCallback('my_drawing',draw_circle) # Connects the mouse button to our callback function


img = np.zeros((512,512,3), dtype = np.int8)  ## blank image

while True:
    cv2.imshow("my_drawing", img)
    
    if cv2.waitKey(20) & 0xFF == 27:  ### my understanding of waitKet: like heartbeat
        break
cv2.destroyAllWindows()



In markdown:  ----  draws a line





***** to list down all the events: use intelliprompt, simply type: cv2.EVENT





event calls for mouse dragging:




import cv2
import numpy as np


# Create a function based on a CV2 Event (Left button click)
drawing = False # True if mouse is pressed
ix,iy = -1,-1

# mouse callback function
def draw_rectangle(event,x,y,flags,param):
    global ix,iy,drawing,mode

    if event == cv2.EVENT_LBUTTONDOWN:
        # When you click DOWN with left mouse button drawing is set to True
        drawing = True
        # Then we take note of where that mouse was located
        ix,iy = x,y

    elif event == cv2.EVENT_MOUSEMOVE:
        # Now the mouse is moving
        if drawing == True:
            # If drawing is True, it means you've already clicked on the left mouse button
            # We draw a rectangle from the previous position to the x,y where the mouse is
            cv2.rectangle(img,(ix,iy),(x,y),(0,255,0),-1)
           

    elif event == cv2.EVENT_LBUTTONUP:
        # Once you lift the mouse button, drawing is False
        drawing = False
        # we complete the rectangle.
        cv2.rectangle(img,(ix,iy),(x,y),(0,255,0),-1)
        
        

# Create a black image
img = np.zeros((512,512,3), np.uint8)
# This names the window so we can reference it 
cv2.namedWindow(winname='my_drawing')
# Connects the mouse button to our callback function
cv2.setMouseCallback('my_drawing',draw_rectangle)

while True: #Runs forever until we break with Esc key on keyboard
    # Shows the image window
    cv2.imshow('my_drawing',img)
    # EXPLANATION FOR THIS LINE OF CODE:
    # https://stackoverflow.com/questions/35372700/whats-0xff-for-in-cv2-waitkey1/39201163
    
    # CHECK TO SEE IF ESC WAS PRESSED ON KEYBOARD
    if cv2.waitKey(1) & 0xFF == 27:
        break
# Once script is done, its usually good practice to call this line
# It closes all windows (just in case you have multiple windows called)
cv2.destroyAllWindows()






/////////////////////////////////////////////////////////////////


fillpoly:

instead of polylines, can use this to create filled out polygon

/////////////////////////////////////////////////////////////////////////


===================================================================

Section 4:

Image Processing

Agenda:

    Learn various Image Processing Operations

    Perform Image operations such as Smoothening, Blurring, Morphological Operations

    Grab Properties such as color spaces and histograms


////////////////////////////////////////////////////////////////////


Color mappings:

So far only worked with RGB color model

colors modeled in combonation of Red, Green and Blue. But very old. 


In 1970 , HSL (Hue, Saturation, Lightness) and HSV (Hue, Saturation, Value) 
were developed as alternative color models


HSL and HSV are more closely alligned with how humans preceive color

We normally work with RGB but generally its a good idea to know how to work with HSV as well




HSL/V is like a cyllinderical model 
  

Hue: Color at any pixel

Saturation: How much Hue (white on inside and color on outsuide)

Lightness: Darkness of that color (black at bottom, white at top)

RGB model: https://en.wikipedia.org/wiki/RGB_color_model

HSV model: https://en.wikipedia.org/wiki/HSL_and_HSV



Code:


## To HSV
img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)

## To HSL
img = cv2.imread(path)
img = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)



Images here are not making much sense as original images are not coded in this way



///////////////////////////////////////////////////////////////////////////////////////


Blending and pasting:


Often we work with multiple images.

OpenCV has many methods of blending images together and pasting images on top of 
each other.


Blending images is done via the addWeighted function of Open CV.

It uses both images and combine them.


For some computer vision systems, we'll want to be able to 
post our own image on top of an already existing image or 
video. We may also want to blend images, maybe we want to 
have a "highlight" effect instead of just a solid box or 
empty rectangle.

Let's explore what is commonly known as **Arithmetic Image 
Operations** with OpenCV. These are referred to as Arithmetic 
Operations because OpenCV is simply performing some common 
math with the pixels for the final effect. 
We'll see a bit of this in our code.

****
For each pixel:
We add some sort of weight to each image's pixel to create a new pixel.

new_pixel = alpha * pixel1 + beta * pixel2 + gamma




Code:

## Different sized images can create problems. We have to create masks to operate in such scenarios
## Right now not creating mask, rather simply resizing the images



img1 =cv2.resize(img1,(1200,1200))
img2 =cv2.resize(img2,(1200,1200))



blended_img = cv2.addWeighted(src1=img1, alpha=0.7, src2 = img2, beta= 0.5, gamma = 0.3)

plt.imshow(blended_img)



## Overlay images of different sizes

## overlay small image on top of larger image (No Blending)

## This is not blending, we are simply adding small imaqge on top of large image

img1 = cv2.imread(path1)
img2 = cv2.imread(path2)
img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2RGB)
img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)
img2 =cv2.resize(img2,(600,600))



large_img = img1
small_img = img2

x_offset = 0
y_offset = 0


large_img[y_offset:y_offset+small_img.shape[0],x_offset:x_offset+small_img.shape[1]] = small_img

#### This is tricky, numpy thinks horizontal row as 2nd axis whereas open cv thinks horizontal row as 1st axis


plt.imshow(large_img)


/////////////////////////////////////////////////////////


## Blending images of Different sizes



What if we want to mask part of smaller image??

 Image  -------> Create MASK ------> Img2 with masked img1


Quite complicated synatx

///////////////////////////////////////////////////////////



Image Thresholding



In some CV applications, it is often necessary to convert color 
images to greyscale, since only edges and shapes end up beinmg important


Simmilarly some applications only require a binary image showing general shapes.


Thresholding is a very simple method of segmenting an image in different parts.

Thresholding will convert an image to consist of only 2 values, white or black



cv2.threshold:


threshold(src, thresh, maxval, type[, dst]) -> retval, dst
.   @brief Applies a fixed-level threshold to each array element.
.   
.   The function applies fixed-level thresholding to a multiple-channel array. The function is typically
.   used to get a bi-level (binary) image out of a grayscale image ( #compare could be also used for
.   this purpose) or for removing a noise, that is, filtering out pixels with too small or too large
.   values. There are several types of thresholding supported by the function. They are determined by
.   type parameter.
.   
.   Also, the special values #THRESH_OTSU or #THRESH_TRIANGLE may be combined with one of the
.   above values. In these cases, the function determines the optimal threshold value using the Otsu's
.   or Triangle algorithm and uses it instead of the specified thresh.
.   
.   @note Currently, the Otsu's and Triangle methods are implemented only for 8-bit single-channel images.
.   
.   @param src input array (multiple-channel, 8-bit or 32-bit floating point).
.   @param dst output array of the same size  and type and the same number of channels as src.
.   @param thresh threshold value.
.   @param maxval maximum value to use with the #THRESH_BINARY and #THRESH_BINARY_INV thresholding
.   types.
.   @param type thresholding type (see #ThresholdTypes).
.   @return the computed threshold value if Otsu's or Triangle methods used.



Ex:

Binary Threshold:

converts everything below threshold value to 0 and everything above to 1.

Normally half way mark is chosen as threshold.

ret, thresh1 = cv2.threshold(src = img, thresh= 127, maxval=255, type=cv2.THRESH_BINARY)


plt.imshow(thresh1, cmap = 'gray')




Binary Inverse:

Opposite of Binary Thresholding

ret, thresh1 = cv2.threshold(src = img, thresh= 127, maxval=255, type=cv2.THRESH_BINARY_INV)



Threshold trunc:

If value is greater than threshold, make the value equal to threshold.

If value is lesser than threshold, retain the value

ret, thresh1 = cv2.threshold(src = img, thresh= 127, maxval=255, type=cv2.THRESH_TRUNC)




Thresh to zero:

Inverse of trucation.

If value > threshold retain the value

Else make the value == threshold



